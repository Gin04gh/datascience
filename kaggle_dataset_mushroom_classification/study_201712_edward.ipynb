{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*2017.12.19*\n",
    "\n",
    "1. 確率的プログラミングライブラリ『Edward』\n",
    "1. ベイジアンニューラルネットワーク with Edward\n",
    "\n",
    "---\n",
    "\n",
    "**1. 確率的プログラミングライブラリ『Edward』**\n",
    "\n",
    "---\n",
    "\n",
    "**Edward**\n",
    "\n",
    "* 公式: [http://edwardlib.org/](http://edwardlib.org/)\n",
    "* 2016年より開発されている確率的プログラミングのPythonライブラリ\n",
    "* Dustin Tran氏(Open AI)が開発をリード\n",
    "* LDAで有名なコロンビア大学のBlei先生の研究室で開発\n",
    "* ベイズ統計と機械学習, 深層学習, 確率的プログラミングを融合させている\n",
    "* 計算にTensorFlowを用いている\n",
    "* 計算速度がStanやPyMC3よりも速い\n",
    "* GPUによる高速化が可能\n",
    "* TensorBoardによる可視化も可能\n",
    "* 統計学者のGeorge Edward Pelham Boxから名前を取っている\n",
    "* TensorFlowにマージされる予定（[Edward is officially moving into TensorFlow](https://discourse.edwardlib.org/t/edward-is-officially-moving-into-tensorflow/387)\n",
    "\n",
    "---\n",
    "\n",
    "**Edwardでできること**\n",
    "\n",
    "ベイズ統計に加えて, 深層学習に対するベイズ適用事例が豊富\n",
    "\n",
    "* ベイズ線形回帰（[Bayesian linear regression](http://edwardlib.org/tutorials/supervised-regression)）\n",
    "* バッチトレーニング（[Batch Training](http://edwardlib.org/tutorials/batch-training)）\n",
    "* Automated Transformations（[Automated Transformations](http://edwardlib.org/tutorials/automated-transformations)）\n",
    "* 線形混合効果モデル（[Linear Mixed Effects Models](http://edwardlib.org/tutorials/linear-mixed-effects-models)）\n",
    "* 混合密度ネットワーク（[Mixture Density Networks](http://edwardlib.org/tutorials/mixture-density-network)）\n",
    "* GAN（[Generative Adversarial Networks](http://edwardlib.org/tutorials/gan)）\n",
    "* 確率的デコーダー（[Probabilistic Decoder](http://edwardlib.org/tutorials/decoder)）\n",
    "* ネットワーク推論（[Inference Networks](http://edwardlib.org/tutorials/inference-networks)）\n",
    "* ベイジアンニューラルネットワーク（[Bayesian Neural Network](http://edwardlib.org/tutorials/bayesian-neural-network)）\n",
    "* 確率的主成分分析（[Probabilistic PCA](http://edwardlib.org/tutorials/probabilistic-pca)）\n",
    "\n",
    "---\n",
    "\n",
    "**ベイズ推論**\n",
    "\n",
    "**1. モデル構築:**\n",
    "\n",
    "観測データの集合 $\\mathcal{D}$ と未知パラメータ $\\theta$ に関して,  \n",
    "モデル $p(\\mathcal{D}, \\theta)=p(\\mathcal{D}|\\theta)p(\\theta)$ を構築する.\n",
    "\n",
    "**2. 推論:**\n",
    "\n",
    "事後分布 $p(\\theta|\\mathcal{D})=\\displaystyle\\frac{p(\\mathcal{D}|\\theta)p(\\theta)}{p(\\mathcal{D})}=\\displaystyle\\frac{p(\\mathcal{D}|\\theta)p(\\theta)}{{\\int}p(\\mathcal{D}|\\theta)p(\\theta)d\\theta}$ を解析的または近似的に求める.\n",
    "\n",
    "---\n",
    "\n",
    "**ベイズ推論**\n",
    "\n",
    "**解析的:** \n",
    "\n",
    "* **自然共益事前分布**\n",
    "\n",
    "**近似的:**\n",
    "\n",
    "* **マルコフ連鎖モンテカルロ法（Markov Chain Monte Carlo; MCMC）**\n",
    "\n",
    "    * $\\theta_i{\\sim}p(\\theta|\\mathcal{D})$ を大量に得る. （サンプリング）\n",
    "\n",
    "\n",
    "* **変分推論（Variational Inference）**  \n",
    "（または**変分近似（Variational Approximation）**）\n",
    "    * 解析しやすい分布 $q(\\theta;\\eta)$ を考える.\n",
    "    * $p(\\theta|\\mathcal{D}){\\approx}q(\\theta;\\eta)$ と近似する.  \n",
    "    → $\\arg\\min_{\\eta}KL(q(\\theta;\\eta){\\parallel}p(\\theta|\\mathcal{D}))$\n",
    "    \n",
    "---\n",
    "\n",
    "**詳しくは**\n",
    "\n",
    "* [『パターン認識と機械学習 上』](https://www.amazon.co.jp/%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98%E3%81%A8%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92-%E4%B8%8A-C-M-%E3%83%93%E3%82%B7%E3%83%A7%E3%83%83%E3%83%97/dp/4621061224/ref=pd_bxgy_14_img_2?_encoding=UTF8&psc=1&refRID=0K0K256F86WPPDGTNH5B)\n",
    "* [『パターン認識と機械学習 下 (ベイズ理論による統計的予測)』](https://www.amazon.co.jp/%E3%83%91%E3%82%BF%E3%83%BC%E3%83%B3%E8%AA%8D%E8%AD%98%E3%81%A8%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92-%E4%B8%8B-%E3%83%99%E3%82%A4%E3%82%BA%E7%90%86%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E7%B5%B1%E8%A8%88%E7%9A%84%E4%BA%88%E6%B8%AC-C-M-%E3%83%93%E3%82%B7%E3%83%A7%E3%83%83%E3%83%97/dp/4621061240/ref=pd_lpo_sbs_14_t_2?_encoding=UTF8&psc=1&refRID=6TB0BR1521KXMGNZZHKT)\n",
    "* [『機械学習スタートアップシリーズ ベイズ推論による機械学習入門』](https://www.amazon.co.jp/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%82%B9%E3%82%BF%E3%83%BC%E3%83%88%E3%82%A2%E3%83%83%E3%83%97%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA-%E3%83%99%E3%82%A4%E3%82%BA%E6%8E%A8%E8%AB%96%E3%81%AB%E3%82%88%E3%82%8B%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E5%85%A5%E9%96%80-KS%E6%83%85%E5%A0%B1%E7%A7%91%E5%AD%A6%E5%B0%82%E9%96%80%E6%9B%B8-%E9%A0%88%E5%B1%B1-%E6%95%A6%E5%BF%97/dp/4061538322/ref=sr_1_fkmr0_2?s=books&ie=UTF8&qid=1513574560&sr=1-2-fkmr0&keywords=MLS+%E3%83%99%E3%82%A4%E3%82%BA)\n",
    "    * [サンプルコードのGitHub](https://github.com/sammy-suyama/BayesBook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python 3.6.6\n",
      "--------------------------------------------------\n",
      "tensorflow 1.4.1\n",
      "edward 1.3.4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import edward as ed\n",
    "\n",
    "from pkg_resources import get_distribution\n",
    "import platform\n",
    "print('python', platform.python_version())\n",
    "print('-'*50)\n",
    "libs = ['tensorflow', 'edward']\n",
    "for lib in libs:\n",
    "    version = get_distribution(lib).version\n",
    "    print(lib, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "25.0\n",
      "[ 1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow\n",
    "\n",
    "x_ = tf.placeholder(tf.float32)\n",
    "y_ = tf.square(x_)\n",
    "z_ = tf.ones([3])\n",
    "\n",
    "sess = tf.Session()\n",
    "x, y, z = sess.run([x_, y_, z_], feed_dict={x_: 5.0})\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20482\n"
     ]
    }
   ],
   "source": [
    "# 正規分布の値を生成\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "x = Normal(loc=0.0, scale=1.0)\n",
    "\n",
    "sess = tf.Session() # or ed.get_session()\n",
    "sample_x = sess.run(x)\n",
    "print(sample_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.11332405 -0.26897946 -0.98958927 -0.58549458  0.67566568  0.38930422\n",
      "  1.51494467 -0.73315859  1.97734773  0.82850665]\n"
     ]
    }
   ],
   "source": [
    "# テンソルで生成可能\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "N = 10\n",
    "x = Normal(loc=tf.zeros([N]), scale=tf.ones([N]))\n",
    "\n",
    "sess = tf.Session() # or ed.get_session()\n",
    "samples_x = sess.run(x)\n",
    "print(samples_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.21112\n",
      "-1.35266\n"
     ]
    }
   ],
   "source": [
    "# 正規分布の平均が正規分布に従うモデルの値を生成\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "mu = Normal(loc=0.0, scale=1.0)\n",
    "x = Normal(loc=mu, scale=1.0)\n",
    "\n",
    "sess = tf.Session()\n",
    "sample_mu, sample_x = sess.run([mu, x])\n",
    "print(sample_mu)\n",
    "print(sample_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.0\n",
      "[ 51.06958771  51.15873718  49.92236328  50.50429916  49.67524719\n",
      "  49.78413773  50.40150452  48.48633194  50.06735992  49.22180939]\n"
     ]
    }
   ],
   "source": [
    "# 計算グラフなので、変数に値を供給して値を生成できる\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "mu_ = tf.placeholder(tf.float32)\n",
    "x = Normal(loc=mu_, scale=1.0, sample_shape=10)\n",
    "\n",
    "sess = tf.Session()\n",
    "mu, samples_x = sess.run([mu_, x], feed_dict={mu_: 50.0})\n",
    "print(mu)\n",
    "print(samples_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 1s | Loss: 255.332\n",
      "13.997\n"
     ]
    }
   ],
   "source": [
    "# 正規分布のパラメータの事後分布を求める（変分推論）\n",
    "\n",
    "from edward.models import Normal\n",
    "\n",
    "N = 30\n",
    "x_train = np.random.randint(10, 20, N) # 10〜20の観測値がN個\n",
    "\n",
    "mu = Normal(loc=0.0, scale=1.0)\n",
    "x = Normal(loc=mu, scale=1.0, sample_shape=N)\n",
    "\n",
    "qmu = Normal(loc=tf.Variable(0.0), scale=1.0)\n",
    "\n",
    "inference = ed.KLqp({mu: qmu}, data={x: x_train})\n",
    "inference.run(n_iter=1000)\n",
    "\n",
    "samples = qmu.sample(100).eval()\n",
    "print(samples.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [100%] ██████████████████████████████ Elapsed: 2s | Acceptance Rate: 0.915\n",
      "14.9748\n"
     ]
    }
   ],
   "source": [
    "# 正規分布のパラメータの事後分布を求める（MCMC）\n",
    "\n",
    "from edward.models import Empirical\n",
    "\n",
    "N = 30\n",
    "x_train = np.random.randint(10, 20, N) # 10〜20の観測値がN個\n",
    "\n",
    "T = 1000\n",
    "mu = Normal(loc=0.0, scale=1.0)\n",
    "x = Normal(loc=mu, scale=1.0, sample_shape=N)\n",
    "\n",
    "qmu = Empirical(tf.Variable(tf.zeros(T)))\n",
    "\n",
    "inference = ed.HMC({mu: qmu}, {x: x_train})\n",
    "inference.run(n_iter=T)\n",
    "\n",
    "samples = qmu.sample(100).eval()\n",
    "print(samples.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. ベイジアンニューラルネットワーク with Edward**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**ベイジアンニューラルネットワーク**\n",
    "\n",
    "* ニューラルネットワークの重み（weights and biases） $\\boldsymbol{w}$ の事後分布を求める.  \n",
    "\n",
    "$$$$\n",
    "$$\\boldsymbol{w}{\\sim}\\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\text{I}})$$\n",
    "$$p(y|\\boldsymbol{x}, \\boldsymbol{w})=\\text{Categorical}\\left(\\frac{\\exp(f(\\boldsymbol{x}, \\boldsymbol{w}))}{\\Sigma\\exp(f(\\boldsymbol{x}, \\boldsymbol{w}))}\\right)$$\n",
    "\n",
    "* メリット\n",
    "    * 過学習を抑えられる\n",
    "    * 予測の不確かさや自信の度合いを定量的に扱える\n",
    "* デメリット\n",
    "    * 計算量\n",
    "    * 再現できない場合がある\n",
    "    \n",
    "---\n",
    "\n",
    "**実装**\n",
    "\n",
    "`bayesian_neural_network_edward.ipynb` 参照\n",
    "\n",
    "---\n",
    "\n",
    "**おまけ**\n",
    "\n",
    "* ベイジアン畳み込みニューラルネットワーク\n",
    "    * [Yarin Gal, Zoubin Ghahramani (2016). Bayesian Convolutional Neural Networks with Bernoulli Approximate Variational Inference](https://arxiv.org/abs/1506.02158)\n",
    "* ベイジアンリカレントニューラルネットワーク\n",
    "    * [Meire Fortunato, Charles Blundell, Oriol Vinyals (2017). Bayesian Recurrent Neural Networks](https://arxiv.org/abs/1704.02798)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
