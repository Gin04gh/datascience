{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 文章データ（日本語）をBinary Relevance Learningでマルチラベル分類を行う\n",
    "* 2値分類器にはナイーブベイズ分類を使う"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevance:\n",
    "    def __init__(self, corpus):\n",
    "        \"\"\"クラスの初期化\n",
    "        \n",
    "        Args:\n",
    "            corpus (string(object) np.array): コーパス\n",
    "        \"\"\"\n",
    "        self.labels = [] # 分類ラベルリスト\n",
    "        self.clfs = {} # 分類器インスタンスリスト\n",
    "        # MeCab\n",
    "        self.index_category = 0\n",
    "        self.index_root_form = 6\n",
    "        self.target_categories = [\"名詞\", \"動詞\", \"形容詞\", \"副詞\", \"連体詞\", \"感動詞\"]\n",
    "        self.stop_words = []\n",
    "        self.mecab = MeCab.Tagger()\n",
    "        # Vectorizer\n",
    "        self.vectorizer = CountVectorizer(binary=True, analyzer=self.analyzer) # BoW, binary\n",
    "        self.vectorizer.fit_transform(corpus)\n",
    "        \n",
    "    def analyzer(self, text):\n",
    "        \"\"\"形態素解析を行う\n",
    "        \n",
    "        Args:\n",
    "            text (string): 文章\n",
    "        Returns:\n",
    "            words:\n",
    "        \"\"\"\n",
    "        if not text:\n",
    "            return []\n",
    "        words = []\n",
    "        node = self.mecab.parseToNode(text)\n",
    "        while node:\n",
    "            word = \"\"\n",
    "            features = node.feature.split(\",\")\n",
    "            if features[self.index_category] in self.target_categories:\n",
    "                if features[self.index_root_form] == \"*\":\n",
    "                    word = node.surface\n",
    "                else:\n",
    "                    word = features[self.index_root_form]\n",
    "            if len(word) > 0 and word not in self.stop_words:\n",
    "                words.append(word)\n",
    "            node = node.next\n",
    "        return words\n",
    "        \n",
    "    def train(self, target_label, positive_x, negative_x):\n",
    "        \"\"\"学習\n",
    "        \n",
    "        Args:\n",
    "            target_label (int): どのラベルの分類器を学習させるか\n",
    "            positive_x (string(object) np.array): 正例の文章リスト\n",
    "            negative_x (string(object) np.array): 負例の文章リスト\n",
    "        Returns:\n",
    "            (bool): \n",
    "        \"\"\"\n",
    "        if not self.exists_label(target_label):\n",
    "            return False\n",
    "        # ペアデータセットにしてシャッフルする\n",
    "        dataset = []\n",
    "        for x in positive_x:\n",
    "            dataset.append((x,1)) # 正例\n",
    "        for x in negative_x:\n",
    "            dataset.append((x,0)) # 負例\n",
    "        dataset = np.array(dataset)\n",
    "        np.random.shuffle(dataset) # シャッフル\n",
    "        x = np.array(dataset[:,0], dtype=\"object\") # 入力\n",
    "        y = np.array(dataset[:,1], dtype=\"int32\") # ラベル\n",
    "        self.clfs[target_label].fit(self.vectorizer.transform(x), y) # 学習            \n",
    "        return True\n",
    "    \n",
    "    def predict(self, x):\n",
    "        \"\"\"予測\n",
    "        \n",
    "        Args:\n",
    "            x: 予測させる文章リスト\n",
    "        Returns:\n",
    "            result: \n",
    "        \"\"\"\n",
    "        result = []\n",
    "        for i in range(len(x)):\n",
    "            result.append([]) # 付与されたラベルを追加していくための配列\n",
    "        for label in self.clfs: # 分類器をループ\n",
    "            y = self.clfs[label].predict(self.vectorizer.transform(x)) # このラベルかどうかを予測\n",
    "            for i, y_ in enumerate(y):\n",
    "                if y_ == 1: # このラベルがつくと予想された\n",
    "                    result[i].append(label)\n",
    "        return result\n",
    "        \n",
    "    def set_labels(self, labels):\n",
    "        \"\"\"ラベルとラベルに対応する分類器インスタンスをセットする\n",
    "        \n",
    "        Args:\n",
    "            labels (int np.array): 追加するラベルリスト\n",
    "        \"\"\"\n",
    "        for label in labels:\n",
    "            self.labels.append(label) # ラベル追加\n",
    "            self.clfs[label] = naive_bayes.MultinomialNB(alpha=1.0) # 分類器インスタンス作成\n",
    "    \n",
    "    def exists_label(self, label):\n",
    "        \"\"\"ラベルが存在するかどうか\n",
    "        \n",
    "        Args:\n",
    "            label (int): 調べるラベル\n",
    "        Returns:\n",
    "            (bool): \n",
    "        \"\"\"\n",
    "        if (label not in self.labels) or (label not in self.clfs):\n",
    "            return False\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using dataset is https://www.rondhuit.com/download.html#ldcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./data/text\"\n",
    "categories = [\"it-life-hack\", \"kaden-channel\", \"sports-watch\"]\n",
    "data = []\n",
    "for category in categories:\n",
    "    files = glob.glob(path + \"/\" + category + \"/\" + category + \"*\")\n",
    "    for file in files:\n",
    "        f = open(file)\n",
    "        data.append((f.read(), categories.index(category))) # ファイルの中身、カテゴリーラベル\n",
    "        f.close()\n",
    "# ファイルの中身が、URL、日付、タイトル、本文と含んでいるので、本文のみにする\n",
    "data_tmp = []\n",
    "for d in data:\n",
    "    x, y = d[0], d[1] # ファイルの中身、カテゴリーラベル\n",
    "    x = x.split(\"\\n\")\n",
    "    x = x[3:] # URL、日付、タイトルを落とす\n",
    "    x = \" \".join(x)\n",
    "    data_tmp.append((x, y)) # 本文、カテゴリーラベル\n",
    "data = data_tmp\n",
    "data = np.array(data)\n",
    "np.random.shuffle(data)\n",
    "br = BinaryRelevance(data[:,0].tolist())\n",
    "br.set_labels([0,1,2])\n",
    "\n",
    "N = 100\n",
    "train0, train1, train2 = [], [], []\n",
    "for d in data:\n",
    "    x, y = d[0], int(d[1])\n",
    "    if y == 0:\n",
    "        train0.append(x)\n",
    "    elif y == 1:\n",
    "        train1.append(x)\n",
    "    elif y == 2:\n",
    "        train2.append(x)\n",
    "train0, train1, tarin2 = train0[:N], train1[:N], train2[:N]\n",
    "\n",
    "negative_x = np.array(train1+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(0, train0, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train2)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(1, train1, negative_x)\n",
    "\n",
    "negative_x = np.array(train0+train1)\n",
    "np.random.shuffle(negative_x)\n",
    "negative_x = negative_x[:N]\n",
    "br.train(2, train2, negative_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "1 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "1 \t [0, 1]\n",
      "2 \t [2]\n",
      "0 \t [0, 1, 2]\n",
      "2 \t [2]\n",
      "1 \t [0, 1]\n",
      "1 \t [0, 1]\n",
      "1 \t [0, 1]\n",
      "1 \t [0, 1]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 2]\n",
      "1 \t [0, 1]\n",
      "1 \t [0, 1]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 2]\n",
      "0 \t [0, 1]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "2 \t [2]\n",
      "1 \t [0, 1]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "0 \t [2]\n",
      "2 \t [2]\n",
      "1 \t [0, 1]\n",
      "0 \t [0, 1]\n",
      "2 \t [2]\n",
      "0 \t [0, 1]\n"
     ]
    }
   ],
   "source": [
    "xs, ys = data[:, 0][-50:], data[:, 1][-50:]\n",
    "\n",
    "preds = br.predict(xs)\n",
    "\n",
    "for y, pred in zip(ys, preds):\n",
    "    print(y, '\\t', pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.6\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alembic==0.9.9\r\n",
      "asn1crypto==0.24.0\r\n",
      "attrs==18.1.0\r\n",
      "Automat==0.0.0\r\n",
      "backcall==0.1.0\r\n",
      "beautifulsoup4==4.6.1\r\n",
      "bleach==2.1.3\r\n",
      "bokeh==0.12.16\r\n",
      "boto==2.49.0\r\n",
      "boto3==1.7.71\r\n",
      "botocore==1.10.71\r\n",
      "bz2file==0.98\r\n",
      "certifi==2018.4.16\r\n",
      "cffi==1.11.5\r\n",
      "chardet==3.0.4\r\n",
      "cloudpickle==0.5.3\r\n",
      "conda==4.5.8\r\n",
      "constantly==15.1.0\r\n",
      "cryptography==2.2.1\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.28.5\r\n",
      "dask==0.18.2\r\n",
      "decorator==4.3.0\r\n",
      "dill==0.2.8.2\r\n",
      "docutils==0.14\r\n",
      "entrypoints==0.2.3\r\n",
      "fastcache==1.0.2\r\n",
      "gensim==3.5.0\r\n",
      "gmpy2==2.0.8\r\n",
      "h5py==2.7.1\r\n",
      "html5lib==1.0.1\r\n",
      "hyperlink==17.3.1\r\n",
      "idna==2.7\r\n",
      "imageio==2.3.0\r\n",
      "incremental==17.5.0\r\n",
      "ipykernel==4.8.2\r\n",
      "ipython==6.5.0\r\n",
      "ipython-genutils==0.2.0\r\n",
      "ipywidgets==7.2.1\r\n",
      "jedi==0.12.1\r\n",
      "Jinja2==2.10\r\n",
      "jmespath==0.9.3\r\n",
      "jsonschema==2.6.0\r\n",
      "jupyter-client==5.2.3\r\n",
      "jupyter-core==4.4.0\r\n",
      "jupyterhub==0.8.1\r\n",
      "jupyterlab==0.33.4\r\n",
      "jupyterlab-launcher==0.11.2\r\n",
      "kiwisolver==1.0.1\r\n",
      "llvmlite==0.23.0\r\n",
      "Mako==1.0.7\r\n",
      "MarkupSafe==1.0\r\n",
      "matplotlib==2.2.2\r\n",
      "mecab-python3==0.7\r\n",
      "mistune==0.8.3\r\n",
      "nbconvert==5.3.1\r\n",
      "nbformat==4.4.0\r\n",
      "networkx==2.1\r\n",
      "notebook==5.6.0\r\n",
      "numba==0.38.1\r\n",
      "numexpr==2.6.6\r\n",
      "numpy==1.13.3\r\n",
      "olefile==0.45.1\r\n",
      "packaging==17.1\r\n",
      "pamela==0.3.0\r\n",
      "pandas==0.23.4\r\n",
      "pandocfilters==1.4.2\r\n",
      "parso==0.3.1\r\n",
      "patsy==0.5.0\r\n",
      "pexpect==4.6.0\r\n",
      "pickleshare==0.7.4\r\n",
      "Pillow==5.2.0\r\n",
      "prometheus-client==0.3.0\r\n",
      "prompt-toolkit==1.0.15\r\n",
      "protobuf==3.5.2\r\n",
      "ptyprocess==0.6.0\r\n",
      "pycosat==0.6.3\r\n",
      "pycparser==2.18\r\n",
      "Pygments==2.2.0\r\n",
      "pyOpenSSL==18.0.0\r\n",
      "pyparsing==2.2.0\r\n",
      "PySocks==1.6.8\r\n",
      "python-dateutil==2.7.3\r\n",
      "python-editor==1.0.3\r\n",
      "python-oauth2==1.0.1\r\n",
      "pytz==2018.5\r\n",
      "PyWavelets==0.5.2\r\n",
      "PyYAML==3.12\r\n",
      "pyzmq==17.1.0\r\n",
      "requests==2.19.1\r\n",
      "rpy2==2.8.5\r\n",
      "ruamel-yaml==0.15.44\r\n",
      "s3transfer==0.1.13\r\n",
      "scikit-image==0.14.0\r\n",
      "scikit-learn==0.19.2\r\n",
      "scipy==1.1.0\r\n",
      "seaborn==0.9.0\r\n",
      "Send2Trash==1.5.0\r\n",
      "simplegeneric==0.8.1\r\n",
      "singledispatch==3.4.0.3\r\n",
      "six==1.11.0\r\n",
      "sklearn==0.0\r\n",
      "smart-open==1.6.0\r\n",
      "SQLAlchemy==1.2.10\r\n",
      "statsmodels==0.9.0\r\n",
      "sympy==1.1.1\r\n",
      "terminado==0.8.1\r\n",
      "testpath==0.3.1\r\n",
      "toolz==0.9.0\r\n",
      "tornado==5.1\r\n",
      "traitlets==4.3.2\r\n",
      "Twisted==17.5.0\r\n",
      "urllib3==1.23\r\n",
      "vincent==0.4.4\r\n",
      "wcwidth==0.1.7\r\n",
      "webencodings==0.5\r\n",
      "widgetsnbextension==3.2.1\r\n",
      "xlrd==1.1.0\r\n",
      "zope.interface==4.5.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
